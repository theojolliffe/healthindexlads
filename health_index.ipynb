{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Health index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two CSVs are required. They can be downloaded here:\n",
    "1) https://drive.google.com/file/d/13DD3nb4VR2guEl6M87qjVMcdn1QjWpzC/view?usp=sharing\n",
    "2) https://drive.google.com/file/d/1Zp2LPEqv6NTdItB1V6osW1oP5SsvbTIc/view?usp=sharing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once CSVs are downloaded change the directory paths below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read main csv data and drop empty column\n",
    "df = pd.read_csv('/Users/theojolliffe/Downloads/All data-Table.csv')\n",
    "df = df.drop(['Unnamed: 7'], axis=1)\n",
    "\n",
    "# Create empty columns we will populate later\n",
    "df[\"Rank\"] = np.nan\n",
    "df[\"Change1year\"] = np.nan\n",
    "df[\"Change3year\"] = np.nan\n",
    "df[\"highestRank\"] = np.nan\n",
    "df[\"highestRankType\"] = np.nan\n",
    "df[\"lowestRank\"] = np.nan\n",
    "df[\"lowestRankType\"] = np.nan\n",
    "df[\"Change1year Rank\"] = np.nan\n",
    "df[\"Change3year Rank\"] = np.nan\n",
    "df['value'] = df['Index value']\n",
    "\n",
    "# Correct spelling mistakes in data\n",
    "df['Indicator/grouping name'] = df['Indicator/grouping name'].replace({'Local enviroment': 'Local environment'})\n",
    "df['Indicator/grouping name'] = df['Indicator/grouping name'].replace({'Public greenspace': 'Public green space'})\n",
    "\n",
    "df[\"Measure\"]=df[\"Indicator/grouping name\"]\n",
    "\n",
    "# Read mapping csv, used later to create hierarchal structure of data (Domains>Subdomains>Indicators)\n",
    "indicator_mapping = pd.read_csv('/Users/theojolliffe/Downloads/indicator_mapping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the hierarchy\n",
    "We need to add columns that hold information about which domain and subdomain each data point belongs to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dfs filtered by index level \n",
    "subdomains = df[df['Index level'] == 'Subdomain']\n",
    "domains = df[df['Index level'] == 'Domain']\n",
    "\n",
    "# Create dictionaries that map indicators to subdomains and subdomains to domains\n",
    "indicator_domain_mapping = indicator_mapping[['Domain', 'Indicator']].set_index('Indicator').to_dict()['Domain']\n",
    "indicator_subdomain_mapping = indicator_mapping[['Subdomain', 'Indicator']].set_index('Indicator').to_dict()['Subdomain']\n",
    "subdomain_domain_mapping = indicator_mapping[['Subdomain', 'Domain']].set_index('Subdomain').to_dict()['Domain']\n",
    "subdomain_subdomain_mapping = {key: key for key in subdomains['Indicator/grouping name'].unique()}\n",
    "domain_domain_mapping = {key: key for key in domains['Indicator/grouping name'].unique()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create domain column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping points function to the correct domain mapping depending on index level of row\n",
    "domain_replacement_mapping = {'Domain': domain_domain_mapping,\n",
    "                             'Subdomain': subdomain_domain_mapping,\n",
    "                             'Indicator': indicator_domain_mapping}\n",
    "\n",
    "# This function finds the correct domain for any indicator, subdomain or domain\n",
    "def get_domain(row):\n",
    "    level = row['Index level']\n",
    "    # Overall health data is stored alongside the domains\n",
    "    if level == 'Overall':\n",
    "        return 'Overall'\n",
    "    replacement_mapping = domain_replacement_mapping[level]\n",
    "    return replacement_mapping[row['Indicator/grouping name']]\n",
    "\n",
    "# Create new column holding domain information\n",
    "df['Domain'] = df.apply(get_domain, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create subdomain and indicator columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points to correct subdomain mapping\n",
    "subdomain_replacement_mapping = {'Subdomain': subdomain_subdomain_mapping,\n",
    "                             'Indicator': indicator_subdomain_mapping}\n",
    "\n",
    "# Finds the correct subdomain for any indicator, subdomain or domain (domain = NaN)\n",
    "def get_subdomain(row):\n",
    "    level = row['Index level']\n",
    "    if level in ['Overall', 'Domain']:\n",
    "        return np.nan\n",
    "    replacement_mapping = subdomain_replacement_mapping[level]\n",
    "    return replacement_mapping[row['Indicator/grouping name']]\n",
    "\n",
    "# Create subdomain column\n",
    "df['Subdomain'] = df.apply(get_subdomain, axis=1)\n",
    "\n",
    "# Create indicator column with NaNs for overall, domain, and subdomain rows\n",
    "df['Indicator'] = df['Indicator/grouping name'].where(df['Index level'] == 'Indicator', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating change over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table that holds the change in value from previous year\n",
    "def get_diffs(group):\n",
    "    # By default diff() calculates the different between a value in the previous row\n",
    "    output = group.sort_values('Year')['Index value'].diff()\n",
    "    output.index = group.sort_values('Year')['Year'].unique().tolist()\n",
    "    return output\n",
    "    \n",
    "# Hold area and indicator the same (index level is held because unemployment appears at two levels)    \n",
    "diff_output = df.groupby(['Area Name', 'Index level', 'Indicator/grouping name']).apply(get_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the original df with 1 year change values\n",
    "def grab_diff(row):\n",
    "    area_name = row['Area Name']\n",
    "    index_level = row['Index level']\n",
    "    indicator_grouping_name = row['Indicator/grouping name']\n",
    "    year = row['Year']\n",
    "    # diff_output is a multi-index table, hence needing three variables in first index position\n",
    "    return diff_output.loc[area_name, index_level, indicator_grouping_name][year]\n",
    "\n",
    "df['Change1year'] = df.apply(grab_diff, axis=1)\n",
    "df['Change1year'] = df['Change1year'].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table that holds the change in value from 3 years ago (for 2018 only)\n",
    "def get_3_year_diff(group):\n",
    "    output = group.sort_values('Year')['Index value']\n",
    "    return output.iloc[-1] - output.iloc[0]\n",
    "    \n",
    "three_year_diff_output = df.groupby(['Area Name', 'Index level', 'Indicator/grouping name']).apply(get_3_year_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the original df with 3 year change values\n",
    "def grab_3_year_diff(row):\n",
    "    year = row['Year']\n",
    "    # Only return a number if we are looking at data for 2018\n",
    "    if year == 2018:\n",
    "        area_name = row['Area Name']\n",
    "        index_level = row['Index level']\n",
    "        indicator_grouping_name = row['Indicator/grouping name']\n",
    "        return three_year_diff_output.loc[area_name, index_level, indicator_grouping_name]\n",
    "    else:\n",
    "        return np.nan\n",
    "df['Change3year'] = df.apply(grab_3_year_diff, axis=1)\n",
    "df['Change3year'] = df['Change3year'].round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create rankings for index value, one year change, and three year change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change NaNs to string \"NaNs\" so it is JSON compatible\n",
    "df = df.fillna(\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function creates sorted list of index values for grouped dataframe\n",
    "def create_rankings(group):\n",
    "    \n",
    "    # Create a sorted list of all index values within group\n",
    "    index_list = group[\"Index value\"].tolist()\n",
    "    index_list.sort(reverse = True)\n",
    "    group[\"Rank\"] = group.apply(input_ranking, index_list=index_list, compare=\"Index value\", axis=1)\n",
    "    \n",
    "    # Create list for one year change\n",
    "    index_list_1year = group[\"Change1year\"].tolist()\n",
    "    index_list_1year.sort(reverse = True)\n",
    "    group[\"Change1year Rank\"] = group.apply(input_ranking, index_list=index_list_1year, compare=\"Change1year\", axis=1)\n",
    "\n",
    "    # Create list for three year change\n",
    "    index_list_3year = group[\"Change3year\"].tolist()\n",
    "    index_list_3year.sort(reverse = True)\n",
    "    group[\"Change3year Rank\"] = group.apply(input_ranking, index_list=index_list_3year, compare=\"Change3year\", axis=1)\n",
    "\n",
    "    return group\n",
    "\n",
    "# Function is called by the create_rankings function and outputs rank per row\n",
    "def input_ranking(row, index_list, compare):\n",
    "    # Find the position of the ith value within the list and add one to give the first rank a value of 1\n",
    "    ind_value = row[compare]\n",
    "    # Don't rank NaNs and also omit top ranks for 0 change\n",
    "    if (ind_value==\"NaN\")|(ind_value==0):\n",
    "        rank = \"NaN\"\n",
    "    else:\n",
    "        rank = index_list.index(ind_value) + 1\n",
    "\n",
    "    return rank\n",
    "\n",
    "# Hold 'Geography type', 'Year', 'Indicator/grouping name', 'Index level' to compare areas\n",
    "df = df.groupby(['Geography type', 'Year', 'Indicator/grouping name', 'Index level']).apply(create_rankings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create object holding number of areas of each geog type\n",
    "area_amounts = {\"National\": len(df[(df[\"Geography type\"]==\"National\") & (df[\"Year\"]==2018) & (df[\"Indicator/grouping name\"]==\"Overall\")]), \"Region\": len(df[(df[\"Geography type\"]==\"Region\") & (df[\"Year\"]==2018) & (df[\"Indicator/grouping name\"]==\"Overall\")]), \"Upper Tier Local Authority\": len(df[(df[\"Geography type\"]==\"Upper Tier Local Authority\") & (df[\"Year\"]==2018) & (df[\"Indicator/grouping name\"]==\"Overall\")])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Of the three rank types, which is the **highest** for each row of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column populated by the highest of the three ranks\n",
    "def highest_rank(row):\n",
    "    row = row.replace(\"NaN\", 400)\n",
    "    \n",
    "    if (row['Rank'] <= row['Change1year Rank']) and (row['Rank'] <= row['Change3year Rank']):\n",
    "        highest = row['Rank']\n",
    "    elif (row['Change1year Rank'] <= row['Rank']) and (row['Change1year Rank'] <= row['Change3year Rank']):\n",
    "        highest = row['Change1year Rank']\n",
    "    elif (row['Change3year Rank'] <= row['Rank']) and (row['Change3year Rank'] <= row['Change1year Rank']):\n",
    "        highest = row['Change3year Rank']\n",
    "    return highest \n",
    "\n",
    "df['highestRank'] = df.apply(highest_rank, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column populated by the type of the highest rank\n",
    "def highest_rank_type(row):\n",
    "    row = row.replace(\"NaN\", 400)\n",
    "    \n",
    "    if (row['Rank'] <= row['Change1year Rank']) and (row['Rank'] <= row['Change3year Rank']):\n",
    "        type_rank = 'Rank'\n",
    "    elif (row['Change1year Rank'] <= row['Rank']) and (row['Change1year Rank'] <= row['Change3year Rank']):\n",
    "        type_rank = 'Change1year Rank'\n",
    "    elif (row['Change3year Rank'] <= row['Rank']) and (row['Change3year Rank'] <= row['Change1year Rank']):\n",
    "        type_rank = 'Change3year Rank'\n",
    "    return type_rank \n",
    "\n",
    "df['highestRankType'] = df.apply(highest_rank_type, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Of the three rank types, which has the **lowest** rank for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column populated by the lowest of the three ranks\n",
    "def lowest_rank(row):\n",
    "    row = row.replace(\"NaN\", 0)\n",
    "    \n",
    "    if (row['Rank'] >= row['Change1year Rank']) and (row['Rank'] >= row['Change3year Rank']):\n",
    "        lowest = row['Rank']\n",
    "    elif (row['Change1year Rank'] >= row['Rank']) and (row['Change1year Rank'] >= row['Change3year Rank']):\n",
    "        lowest = row['Change1year Rank']\n",
    "    elif (row['Change3year Rank'] >= row['Rank']) and (row['Change3year Rank'] >= row['Change1year Rank']):\n",
    "        lowest = row['Change3year Rank']\n",
    "    return (1+area_amounts[row[\"Geography type\"]]) - lowest \n",
    "\n",
    "df['lowestRank'] = df.apply(lowest_rank, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column populated by the lowest of the three ranks\n",
    "def lowest_rank_type(row):\n",
    "    row = row.replace(\"NaN\", 0)\n",
    "    \n",
    "    if (row['Rank'] >= row['Change1year Rank']) and (row['Rank'] >= row['Change3year Rank']):\n",
    "        type_rank = 'Rank'\n",
    "    elif (row['Change1year Rank'] >= row['Rank']) and (row['Change1year Rank'] >= row['Change3year Rank']):\n",
    "        type_rank = 'Change1year Rank'\n",
    "    elif (row['Change3year Rank'] >= row['Rank']) and (row['Change3year Rank'] >= row['Change1year Rank']):\n",
    "        type_rank = 'Change3year Rank'\n",
    "    return type_rank \n",
    "\n",
    "df['lowestRankType'] = df.apply(lowest_rank_type, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns containing high/low rank data with unified title for ease of JS indexing\n",
    "def high_low(row):\n",
    "    if row[\"lowestRank\"] < row[\"highestRank\"]:\n",
    "        highest = row[\"lowestRank\"]\n",
    "    elif row[\"lowestRank\"] >= row[\"highestRank\"]:\n",
    "        highest = row[\"highestRank\"]\n",
    "    return highest\n",
    "df['hlRank'] = df.apply(high_low, axis=1)\n",
    "\n",
    "def high_low_type(row):\n",
    "    if row[\"lowestRank\"] < row[\"highestRank\"]:\n",
    "        highest = row[\"lowestRankType\"]\n",
    "    elif row[\"lowestRank\"] >= row[\"highestRank\"]:\n",
    "        highest = row[\"highestRankType\"]\n",
    "    return highest\n",
    "df['hlRankType'] = df.apply(high_low_type, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a nested dictionary which will be exported as a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******\n",
      "      Area Code   Area Name              Geography type  Year Index level  \\\n",
      "7631  E08000003  Manchester  Upper Tier Local Authority  2018   Subdomain   \n",
      "\n",
      "     Indicator/grouping name  Index value  Rank Change1year Change3year  \\\n",
      "7631               Mortality         78.3   148         3.0         4.0   \n",
      "\n",
      "      highestRank   highestRankType  lowestRank lowestRankType  \\\n",
      "7631            8  Change1year Rank           2           Rank   \n",
      "\n",
      "     Change1year Rank Change3year Rank  value    Measure          Domain  \\\n",
      "7631                8               14   78.3  Mortality  Healthy People   \n",
      "\n",
      "      Subdomain Indicator  hlRank hlRankType  \n",
      "7631  Mortality       NaN       2       Rank  \n",
      "*******\n",
      "      Area Code   Area Name              Geography type  Year Index level  \\\n",
      "7631  E08000003  Manchester  Upper Tier Local Authority  2018   Subdomain   \n",
      "\n",
      "     Indicator/grouping name  Index value  Rank Change1year Change3year  \\\n",
      "7631               Mortality         78.3   148         3.0         4.0   \n",
      "\n",
      "      highestRank   highestRankType  lowestRank lowestRankType  \\\n",
      "7631            8  Change1year Rank           2           Rank   \n",
      "\n",
      "     Change1year Rank Change3year Rank  value    Measure          Domain  \\\n",
      "7631                8               14   78.3  Mortality  Healthy People   \n",
      "\n",
      "      Subdomain Indicator  hlRank hlRankType  \n",
      "7631  Mortality       NaN       2       Rank  \n",
      "*******\n",
      "        Measure  highestRank   highestRankType Index level          Domain  \\\n",
      "7631  Mortality            8  Change1year Rank   Subdomain  Healthy People   \n",
      "\n",
      "      Subdomain Indicator  value Change1year Change3year  \n",
      "7631  Mortality       NaN   78.3         3.0         4.0  \n",
      "*******\n",
      "[{'Measure': 'Mortality', 'highestRank': 8, 'highestRankType': 'Change1year Rank', 'Index level': 'Subdomain', 'Domain': 'Healthy People', 'Subdomain': 'Mortality', 'Indicator': 'NaN', 'value': 78.3, 'Change1year': 3.0, 'Change3year': 4.0}]\n"
     ]
    }
   ],
   "source": [
    "def produce_json_for_area_code(group):\n",
    "    output_dict = {}\n",
    "    \n",
    "    # Base level info about the selected area\n",
    "    output_dict['area'] = group.name\n",
    "    output_dict['name'] = group['Area Name'].iloc[0]\n",
    "    output_dict['type'] = group['Geography type'].iloc[0]\n",
    "    \n",
    "    if group['Area Name'].iloc[0] == 'Manchester':\n",
    "        dfTemp = group[group[\"Indicator/grouping name\"]==\"Mortality\"]\n",
    "        print(\"*******\")\n",
    "        print(dfTemp[dfTemp[\"Year\"]==2018])\n",
    "        print(\"*******\")\n",
    "        print(dfTemp[dfTemp[\"Year\"]==2018].sort_values('highestRank'))\n",
    "        print(\"*******\")\n",
    "        print(dfTemp[dfTemp[\"Year\"]==2018].sort_values('highestRank')[['Measure', 'highestRank', 'highestRankType', 'Index level', 'Domain', 'Subdomain', 'Indicator', 'value', 'Change1year', 'Change3year']])\n",
    "        print(\"*******\")\n",
    "        print(dfTemp[dfTemp[\"Year\"]==2018].sort_values('highestRank')[['Measure', 'highestRank', 'highestRankType', 'Index level', 'Domain', 'Subdomain', 'Indicator', 'value', 'Change1year', 'Change3year']].to_dict(orient='records')[:20])\n",
    "    \n",
    "    # A base level object which contains data about the top and bottom ranked indicators for each area\n",
    "    output_dict['priority2018'] = {}\n",
    "    pri_group_high = group[group[\"Year\"]==2018].sort_values('highestRank')\n",
    "    pri_group_low = group[group[\"Year\"]==2018].sort_values('lowestRank')\n",
    "    output_dict['priority2018'][\"Highest\"] = pri_group_high[['Measure', 'highestRank', 'highestRankType', 'Index level', 'Domain', 'Subdomain', 'Indicator', 'value', 'Change1year', 'Change3year']].to_dict(orient='records')[:20]\n",
    "    output_dict['priority2018'][\"Lowest\"] = pri_group_low[['Measure', 'lowestRank', 'lowestRankType', 'Index level', 'Domain', 'Subdomain', 'Indicator', 'value', 'Change1year', 'Change3year']].to_dict(orient='records')[:20]\n",
    "    \n",
    "    # The nested object containing all the data with hierarchal structure\n",
    "    output_dict['data'] = {}\n",
    "    group = group.set_index('Index level')\n",
    "    \n",
    "    # Create an object for each of the three domains, plus 'overall'\n",
    "    for domain in group['Domain'].unique():\n",
    "        output_dict['data'][domain] = {}\n",
    "        \n",
    "        # Data for the total values of each domain \n",
    "        domain_level_totals = group[group['Indicator/grouping name'] == domain].sort_values('Year').set_index('Year')\n",
    "        output_dict['data'][domain]['total'] = domain_level_totals[['value', 'Rank', 'Change1year', 'Change3year', 'Change1year Rank', 'Change3year Rank']].to_dict(orient='index')\n",
    "        \n",
    "        # Besides 'total' object create 'subdomains'\n",
    "        output_dict['data'][domain]['subdomains'] = {}\n",
    "        \n",
    "        # Find each subdomains associated with this domain\n",
    "        rows_with_corresponding_domain = group[group['Domain'] == domain]\n",
    "        for subdomain in rows_with_corresponding_domain['Subdomain'].unique():\n",
    "            if subdomain != 'NaN':\n",
    "                \n",
    "                # Add data for the total value of this subdomain \n",
    "                subdomain_level_totals = group[(group['Indicator/grouping name'] == subdomain) & (group['Indicator']==\"NaN\")].sort_values('Year').set_index('Year') \n",
    "                output_dict['data'][domain]['subdomains'][subdomain] = {}\n",
    "                output_dict['data'][domain]['subdomains'][subdomain]['total'] = subdomain_level_totals[['value', 'Rank', 'Change1year', 'Change3year', 'Change1year Rank', 'Change3year Rank']].to_dict(orient='index')\n",
    "                \n",
    "                # Find the rows for indicators within this subdomain\n",
    "                rows_with_corresponding_subdomain = group[group['Subdomain'] == subdomain]\n",
    "                subset = rows_with_corresponding_subdomain[rows_with_corresponding_subdomain['Indicator']!=\"NaN\"][['Indicator', 'value', 'Rank', 'Change1year', 'Change3year', 'Change1year Rank', 'Change3year Rank', 'Year']].set_index(['Indicator', 'Year'])\n",
    "                \n",
    "                # Store indicator level data within the subdomain\n",
    "                output_dict['data'][domain]['subdomains'][subdomain]['indicators'] = subset.groupby(level=0).apply(lambda df: df.xs(df.name).to_dict(orient='index')).to_dict()\n",
    "    \n",
    "    return output_dict\n",
    "\n",
    "data_dict = df.groupby('Area Code').apply(produce_json_for_area_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save each area as a seperate JSON file\n",
    "Change the root file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data_dict)):\n",
    "    with open('/Users/theojolliffe/Documents/healthindexlads/'+data_dict[i]['area']+'.json', 'w') as outfile:\n",
    "        json.dump(data_dict[i], outfile)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 1f4cd57] Add files\n",
      " 164 files changed, 2017 insertions(+), 159 deletions(-)\n",
      " create mode 100644 .ipynb_checkpoints/CSV Filter Area Names-checkpoint.ipynb\n",
      " create mode 100644 .ipynb_checkpoints/health_index-checkpoint.ipynb\n",
      " create mode 100644 CSV Filter Area Names.ipynb\n",
      " rewrite E06000001.json (93%)\n",
      " rewrite E06000002.json (93%)\n",
      " rewrite E06000003.json (92%)\n",
      " rewrite E06000004.json (92%)\n",
      " rewrite E06000005.json (93%)\n",
      " rewrite E06000006.json (93%)\n",
      " rewrite E06000007.json (94%)\n",
      " rewrite E06000008.json (93%)\n",
      " rewrite E06000009.json (92%)\n",
      " rewrite E06000010.json (93%)\n",
      " rewrite E06000011.json (92%)\n",
      " rewrite E06000012.json (93%)\n",
      " rewrite E06000013.json (93%)\n",
      " rewrite E06000014.json (91%)\n",
      " rewrite E06000015.json (92%)\n",
      " rewrite E06000016.json (92%)\n",
      " rewrite E06000018.json (92%)\n",
      " rewrite E06000019.json (94%)\n",
      " rewrite E06000020.json (92%)\n",
      " rewrite E06000021.json (92%)\n",
      " rewrite E06000022.json (93%)\n",
      " rewrite E06000023.json (92%)\n",
      " rewrite E06000024.json (93%)\n",
      " rewrite E06000025.json (92%)\n",
      " rewrite E06000026.json (94%)\n",
      " rewrite E06000027.json (92%)\n",
      " rewrite E06000030.json (92%)\n",
      " rewrite E06000031.json (92%)\n",
      " rewrite E06000032.json (92%)\n",
      " rewrite E06000033.json (93%)\n",
      " rewrite E06000034.json (91%)\n",
      " rewrite E06000035.json (93%)\n",
      " rewrite E06000037.json (91%)\n",
      " rewrite E06000038.json (93%)\n",
      " rewrite E06000039.json (92%)\n",
      " rewrite E06000040.json (92%)\n",
      " rewrite E06000041.json (92%)\n",
      " rewrite E06000042.json (92%)\n",
      " rewrite E06000043.json (91%)\n",
      " rewrite E06000044.json (93%)\n",
      " rewrite E06000045.json (92%)\n",
      " rewrite E06000046.json (93%)\n",
      " rewrite E06000047.json (93%)\n",
      " rewrite E06000049.json (93%)\n",
      " rewrite E06000050.json (93%)\n",
      " rewrite E06000052.json (93%)\n",
      " rewrite E06000055.json (93%)\n",
      " rewrite E06000056.json (93%)\n",
      " rewrite E06000057.json (92%)\n",
      " rewrite E06000058.json (93%)\n",
      " rewrite E06000060.json (93%)\n",
      " rewrite E08000001.json (93%)\n",
      " rewrite E08000002.json (92%)\n",
      " rewrite E08000003.json (94%)\n",
      " rewrite E08000004.json (92%)\n",
      " rewrite E08000005.json (93%)\n",
      " rewrite E08000006.json (93%)\n",
      " rewrite E08000007.json (92%)\n",
      " rewrite E08000008.json (91%)\n",
      " rewrite E08000009.json (92%)\n",
      " rewrite E08000010.json (92%)\n",
      " rewrite E08000011.json (93%)\n",
      " rewrite E08000012.json (92%)\n",
      " rewrite E08000013.json (93%)\n",
      " rewrite E08000014.json (93%)\n",
      " rewrite E08000015.json (92%)\n",
      " rewrite E08000016.json (92%)\n",
      " rewrite E08000017.json (93%)\n",
      " rewrite E08000018.json (90%)\n",
      " rewrite E08000019.json (92%)\n",
      " rewrite E08000021.json (92%)\n",
      " rewrite E08000022.json (92%)\n",
      " rewrite E08000023.json (92%)\n",
      " rewrite E08000024.json (93%)\n",
      " rewrite E08000025.json (92%)\n",
      " rewrite E08000026.json (93%)\n",
      " rewrite E08000027.json (93%)\n",
      " rewrite E08000028.json (92%)\n",
      " rewrite E08000029.json (93%)\n",
      " rewrite E08000030.json (93%)\n",
      " rewrite E08000031.json (92%)\n",
      " rewrite E08000032.json (93%)\n",
      " rewrite E08000033.json (93%)\n",
      " rewrite E08000034.json (92%)\n",
      " rewrite E08000035.json (92%)\n",
      " rewrite E08000036.json (92%)\n",
      " rewrite E08000037.json (93%)\n",
      " rewrite E09000002.json (93%)\n",
      " rewrite E09000003.json (93%)\n",
      " rewrite E09000004.json (94%)\n",
      " rewrite E09000005.json (92%)\n",
      " rewrite E09000006.json (91%)\n",
      " rewrite E09000007.json (92%)\n",
      " rewrite E09000008.json (93%)\n",
      " rewrite E09000009.json (93%)\n",
      " rewrite E09000010.json (92%)\n",
      " rewrite E09000011.json (93%)\n",
      " rewrite E09000012.json (92%)\n",
      " rewrite E09000013.json (91%)\n",
      " rewrite E09000014.json (91%)\n",
      " rewrite E09000015.json (91%)\n",
      " rewrite E09000016.json (93%)\n",
      " rewrite E09000017.json (91%)\n",
      " rewrite E09000018.json (93%)\n",
      " rewrite E09000019.json (91%)\n",
      " rewrite E09000020.json (92%)\n",
      " rewrite E09000021.json (92%)\n",
      " rewrite E09000022.json (92%)\n",
      " rewrite E09000023.json (92%)\n",
      " rewrite E09000024.json (94%)\n",
      " rewrite E09000025.json (92%)\n",
      " rewrite E09000026.json (94%)\n",
      " rewrite E09000027.json (92%)\n",
      " rewrite E09000028.json (91%)\n",
      " rewrite E09000029.json (93%)\n",
      " rewrite E09000030.json (91%)\n",
      " rewrite E09000031.json (93%)\n",
      " rewrite E09000032.json (92%)\n",
      " rewrite E09000033.json (91%)\n",
      " rewrite E10000003.json (91%)\n",
      " rewrite E10000006.json (93%)\n",
      " rewrite E10000007.json (92%)\n",
      " rewrite E10000008.json (94%)\n",
      " rewrite E10000011.json (94%)\n",
      " rewrite E10000012.json (93%)\n",
      " rewrite E10000013.json (92%)\n",
      " rewrite E10000014.json (91%)\n",
      " rewrite E10000015.json (92%)\n",
      " rewrite E10000016.json (93%)\n",
      " rewrite E10000017.json (92%)\n",
      " rewrite E10000018.json (92%)\n",
      " rewrite E10000019.json (93%)\n",
      " rewrite E10000020.json (93%)\n",
      " rewrite E10000021.json (93%)\n",
      " rewrite E10000023.json (92%)\n",
      " rewrite E10000024.json (93%)\n",
      " rewrite E10000025.json (90%)\n",
      " rewrite E10000027.json (92%)\n",
      " rewrite E10000028.json (93%)\n",
      " rewrite E10000029.json (93%)\n",
      " rewrite E10000030.json (94%)\n",
      " rewrite E10000031.json (92%)\n",
      " rewrite E10000034.json (94%)\n",
      " rewrite E12000001.json (89%)\n",
      " rewrite E12000002.json (90%)\n",
      " rewrite E12000003.json (91%)\n",
      " rewrite E12000004.json (90%)\n",
      " rewrite E12000005.json (91%)\n",
      " rewrite E12000006.json (91%)\n",
      " rewrite E12000007.json (90%)\n",
      " rewrite E12000008.json (90%)\n",
      " rewrite E12000009.json (92%)\n",
      " rewrite E92000001.json (81%)\n",
      " create mode 100644 health_index.ipynb\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"Add files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating objects: 310, done.\n",
      "Counting objects: 100% (310/310), done.\n",
      "Delta compression using up to 16 threads\n",
      "Compressing objects: 100% (166/166), done.\n",
      "Writing objects: 100% (166/166), 177.45 KiB | 1.99 MiB/s, done.\n",
      "Total 166 (delta 160), reused 0 (delta 0), pack-reused 0\n",
      "remote: Resolving deltas: 100% (160/160), completed with 143 local objects.\u001b[K\n",
      "To https://github.com/theojolliffe/healthindexlads.git\n",
      "   97b9c39..1f4cd57  main -> main\n",
      "Branch 'main' set up to track remote branch 'main' from 'origin'.\n"
     ]
    }
   ],
   "source": [
    "!git push -u origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'National', 'Region', 'Upper Tier Local Authority'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/theojolliffe/Downloads/All data-Table.csv')\n",
    "df = df.drop(['Unnamed: 7'], axis=1)\n",
    "set(df['Geography type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents = pd.read_csv('/Users/theojolliffe/Documents/healthindexlads/csv/includedHealthAreas.csv')\n",
    "for (i, j) in enumerate(dfTemp['Area Name']):\n",
    "    num = i+1\n",
    "    if j not in set(parents['name']):\n",
    "        print(j)\n",
    "        parents.loc[-num] = [0, 0, j, 'NaN', 'lad', 'unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-63-ef6d46aa7e58>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subdomains['parents'] = [parents[parents['name']==i].iloc[0]['parent'] for i in subdomains['Area Name']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area Code</th>\n",
       "      <th>Area Name</th>\n",
       "      <th>Geography type</th>\n",
       "      <th>Year</th>\n",
       "      <th>Index level</th>\n",
       "      <th>Indicator/grouping name</th>\n",
       "      <th>Index value</th>\n",
       "      <th>parents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3227</th>\n",
       "      <td>E06000001</td>\n",
       "      <td>Hartlepool</td>\n",
       "      <td>Upper Tier Local Authority</td>\n",
       "      <td>2018</td>\n",
       "      <td>Subdomain</td>\n",
       "      <td>Physiological risk factors</td>\n",
       "      <td>84.6</td>\n",
       "      <td>E12000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>E06000002</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>Upper Tier Local Authority</td>\n",
       "      <td>2018</td>\n",
       "      <td>Subdomain</td>\n",
       "      <td>Physiological risk factors</td>\n",
       "      <td>96.2</td>\n",
       "      <td>E12000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>E06000003</td>\n",
       "      <td>Redcar and Cleveland</td>\n",
       "      <td>Upper Tier Local Authority</td>\n",
       "      <td>2018</td>\n",
       "      <td>Subdomain</td>\n",
       "      <td>Physiological risk factors</td>\n",
       "      <td>79.2</td>\n",
       "      <td>E12000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>E06000004</td>\n",
       "      <td>Stockton-on-Tees</td>\n",
       "      <td>Upper Tier Local Authority</td>\n",
       "      <td>2018</td>\n",
       "      <td>Subdomain</td>\n",
       "      <td>Physiological risk factors</td>\n",
       "      <td>91.5</td>\n",
       "      <td>E12000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>E06000005</td>\n",
       "      <td>Darlington</td>\n",
       "      <td>Upper Tier Local Authority</td>\n",
       "      <td>2018</td>\n",
       "      <td>Subdomain</td>\n",
       "      <td>Physiological risk factors</td>\n",
       "      <td>87.2</td>\n",
       "      <td>E12000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13339</th>\n",
       "      <td>E10000029</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>Upper Tier Local Authority</td>\n",
       "      <td>2018</td>\n",
       "      <td>Subdomain</td>\n",
       "      <td>Crime</td>\n",
       "      <td>115.3</td>\n",
       "      <td>unk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13343</th>\n",
       "      <td>E10000030</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>Upper Tier Local Authority</td>\n",
       "      <td>2018</td>\n",
       "      <td>Subdomain</td>\n",
       "      <td>Crime</td>\n",
       "      <td>99.6</td>\n",
       "      <td>unk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13347</th>\n",
       "      <td>E10000031</td>\n",
       "      <td>Warwickshire</td>\n",
       "      <td>Upper Tier Local Authority</td>\n",
       "      <td>2018</td>\n",
       "      <td>Subdomain</td>\n",
       "      <td>Crime</td>\n",
       "      <td>114.9</td>\n",
       "      <td>unk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13351</th>\n",
       "      <td>E10000032</td>\n",
       "      <td>West Sussex</td>\n",
       "      <td>Upper Tier Local Authority</td>\n",
       "      <td>2018</td>\n",
       "      <td>Subdomain</td>\n",
       "      <td>Crime</td>\n",
       "      <td>99.8</td>\n",
       "      <td>unk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13355</th>\n",
       "      <td>E10000034</td>\n",
       "      <td>Worcestershire</td>\n",
       "      <td>Upper Tier Local Authority</td>\n",
       "      <td>2018</td>\n",
       "      <td>Subdomain</td>\n",
       "      <td>Crime</td>\n",
       "      <td>115.9</td>\n",
       "      <td>unk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2533 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Area Code             Area Name              Geography type  Year  \\\n",
       "3227   E06000001            Hartlepool  Upper Tier Local Authority  2018   \n",
       "3231   E06000002         Middlesbrough  Upper Tier Local Authority  2018   \n",
       "3235   E06000003  Redcar and Cleveland  Upper Tier Local Authority  2018   \n",
       "3239   E06000004      Stockton-on-Tees  Upper Tier Local Authority  2018   \n",
       "3243   E06000005            Darlington  Upper Tier Local Authority  2018   \n",
       "...          ...                   ...                         ...   ...   \n",
       "13339  E10000029               Suffolk  Upper Tier Local Authority  2018   \n",
       "13343  E10000030                Surrey  Upper Tier Local Authority  2018   \n",
       "13347  E10000031          Warwickshire  Upper Tier Local Authority  2018   \n",
       "13351  E10000032           West Sussex  Upper Tier Local Authority  2018   \n",
       "13355  E10000034        Worcestershire  Upper Tier Local Authority  2018   \n",
       "\n",
       "      Index level     Indicator/grouping name  Index value    parents  \n",
       "3227    Subdomain  Physiological risk factors         84.6  E12000001  \n",
       "3231    Subdomain  Physiological risk factors         96.2  E12000001  \n",
       "3235    Subdomain  Physiological risk factors         79.2  E12000001  \n",
       "3239    Subdomain  Physiological risk factors         91.5  E12000001  \n",
       "3243    Subdomain  Physiological risk factors         87.2  E12000001  \n",
       "...           ...                         ...          ...        ...  \n",
       "13339   Subdomain                       Crime        115.3        unk  \n",
       "13343   Subdomain                       Crime         99.6        unk  \n",
       "13347   Subdomain                       Crime        114.9        unk  \n",
       "13351   Subdomain                       Crime         99.8        unk  \n",
       "13355   Subdomain                       Crime        115.9        unk  \n",
       "\n",
       "[2533 rows x 8 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subdomains = df[(df['Index level']=='Subdomain')&(df['Year']==2018)&(df['Geography type']=='Upper Tier Local Authority')]\n",
    "subdomains['parents'] = [parents[parents['name']==i].iloc[0]['parent'] for i in subdomains['Area Name']]\n",
    "subdomains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in set(subdomains['Indicator/grouping name']):\n",
    "    dfTemp = subdomains[subdomains['Indicator/grouping name']==i]\n",
    "    dfTemp.to_csv('/Users/theojolliffe/Documents/healthindexlads/'+i+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
